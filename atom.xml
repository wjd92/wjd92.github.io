<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BOC&#39;s warehouse</title>
  
  
  <link href="http://www.bumpchicken.cn/atom.xml" rel="self"/>
  
  <link href="http://www.bumpchicken.cn/"/>
  <updated>2022-05-08T05:01:49.016Z</updated>
  <id>http://www.bumpchicken.cn/</id>
  
  <author>
    <name>wjd</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>孤立森林原理详解</title>
    <link href="http://www.bumpchicken.cn/2020/05/25/IsolationTree/"/>
    <id>http://www.bumpchicken.cn/2020/05/25/IsolationTree/</id>
    <published>2020-05-25T03:33:00.000Z</published>
    <updated>2022-05-08T05:01:49.016Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://images.bumpchicken.cn/img/tree.png" /></p><p>孤立森林（IsolationForest）是周志华团队于2008年提出的一种具有线性复杂度的异常检测算法，被工业界广泛应用于诸如异常流量检测,金融欺诈行为检测等场景。</p><span id="more"></span><h2 id="算法原理">算法原理</h2><p>异常检测领域，通常是正常的样本占大多数，离群点占绝少数，因此大多数异常检测算法的基本思想都是对正常点构建模型，然后根据规则识别出不属于正常点模型的离群点，比较典型的算法有OneClass SVM(OCSVM), Local OutlierFactor(LOF)。和多数异常检测算法不同，孤立森林采用了一种较为高效的异常发现算法，其思路很朴素，但也足够直观有效。</p><p>考虑以下场景，一个二维平面上零零散散分布着一些点，随机使用分割线对其进行分割，直至所有但点都不可再划分（即被孤立了）。直观上来讲，可以发现那些密度很高的簇需要被切割很多次才会停止切割，但是密度很低的点很快就会停止切割到某个子空间了。</p><p><img src="https://images.bumpchicken.cn/img/20220424235501.png" width="90%" height="50%"></p><p>孤立森林分<b>训练</b>和<b>异常评估</b>两部分:</p><ul><li><b>训练:</b> 根据样本抽样构建多棵iTree，形成孤立森林</li><li><b>异常评估:</b>根据训练过程构建的孤立森林，计算待评估值的异常得分</li></ul><h2 id="训练">训练</h2><ol type="1"><li>给定训练数据集<spanclass="math inline">\(X\)</span>，确定需要构建的孤立树（iTree）个数t，按<spanclass="math inline">\(\phi\)</span>采样大小随机取样作为子样本集<spanclass="math inline">\(X^{&#39;}\)</span></li><li>在子样本集<spanclass="math inline">\(X^{&#39;}\)</span>上构建一棵孤立树(iTree)，过程如下图所示：</li></ol><p><img src="https://images.bumpchicken.cn/img/20220508001729.png" width="80%" height="20%"></p><ol type="a"><li><p>在<spanclass="math inline">\(X\)</span>中随机选择一个属性（维度），在当前样本数据范围内，随机产生一个分割点<spanclass="math inline">\(p\)</span>(介于当前维度最大和最小值之间)</p></li><li><p>此切割点即是一个超平面，将当前节点数据空间切分成2个子空间：将当前所选维度下小于p点的放在当前节点左分支，把大于p点的放在当前节点的右分支</p></li><li><p>在节点的左分支和右分支递归执行步骤a，b，不断构造新的叶子节点，直到叶子节点上只有一个数据或者树已经生长到了限制的高度</p></li><li><p>单棵iTree构建完成</p></li></ol><ol start="3" type="1"><li>按2的过程，依次构建t棵iTree，得到孤立森林</li></ol><p><img src="https://images.bumpchicken.cn/img/20220508003153.png" width="80%" height="30%"></p><h2 id="异常评估">异常评估</h2><p>构建了孤立森林(IForest)后，可以评估某个点<spanclass="math inline">\(x\)</span>的异常得分，用到如下公式:</p><p><span class="math display">\[s(x,n)=2^{-\frac{E(h(x))}{c(n}}\]</span></p><p>其中，<span class="math inline">\(h(x)\)</span> 表示<spanclass="math inline">\(x\)</span>在某棵孤立树中的路径长度，<spanclass="math inline">\(E(h(x))\)</span>表示在所有孤立树中的期望路径长度。<spanclass="math inline">\(c(n)\)</span>为样本数为n时的二叉排序树(BST)的平均搜索路径长度，用来对样本<spanclass="math inline">\(x\)</span>的期望路径长度做归一化处理。<spanclass="math inline">\(c(n)\)</span>公式如下:</p><p><span class="math display">\[c(n)=2H(n-1)-(2(n-1)/n)\]</span></p><p>其中，<span class="math inline">\(H(i)\)</span>是一个调和数，约等于<span class="math inline">\(ln(i) + \gamma\)</span>，<spanclass="math inline">\(\gamma\)</span>为欧拉常数，约等于0.5772156649</p><p>论文对于异常得分分布有如下结论：</p><ol type="1"><li><p>如果异常得分接近1，那么一定是异常点</p></li><li><p>如果异常得分远小于0.5, 那么一定不是异常点</p></li><li><p>如果样本点的异常得分均在0.5左右，那么样本中可能不存在异常点</p></li></ol><p>异常得分<span class="math inline">\(s\)</span>和<spanclass="math inline">\(E(h(x))\)</span>关系图如下所示</p><p><img src="https://images.bumpchicken.cn/img/20220508010609.png" width="50%" height="30%"></p><p>异常得分的等高线图如下所示，通常潜在的异常点<spanclass="math inline">\(s&gt;=0.6\)</span><img src="http://images.bumpchicken.cn/img/20220508010909.png" width="50%" height="30%"></p><h2 id="参考资料">参考资料</h2><p>1.Liu F T, Ting K M, Zhou Z H. Isolation forest[C]//2008 Eighth IEEEInternational Conference on Data Mining. IEEE, 2008: 413-422.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://images.bumpchicken.cn/img/tree.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;孤立森林（Isolation
Forest）是周志华团队于2008年提出的一种具有线性复杂度的异常检测算法，被工业界广泛应用于诸如异常流量检测,金融欺诈行为检测等场景。&lt;/p&gt;</summary>
    
    
    
    <category term="异常检测" scheme="http://www.bumpchicken.cn/categories/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
    
    <category term="异常检测" scheme="http://www.bumpchicken.cn/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>DBSCAN算法原理</title>
    <link href="http://www.bumpchicken.cn/2018/09/25/Dbscan/"/>
    <id>http://www.bumpchicken.cn/2018/09/25/Dbscan/</id>
    <published>2018-09-25T08:00:00.000Z</published>
    <updated>2022-05-08T15:19:41.026Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://images.bumpchicken.cn/img/20220508173927.png" width="60%" height="20%"></p><p>DBSCAN(Density-Based Spatial Clustering of Application withNoise)是一种基于密度的空间聚类算法。该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据中发现任意形状的簇，它将簇定义为密度相连的点的最大集合。算法无需事先指定聚类中心数目，可以对大规模无规则形状的数据进行有效聚类。</p><span id="more"></span><h2 id="相关定义">相关定义</h2><p>DBSCAN有自己的一套符号体系，定义了许多新概念，数学体系十分严谨</p><h3 id="密度定义">密度定义</h3><p>给定数据集<span class="math inline">\(D\)</span></p><ul><li><span class="math inline">\(\epsilon\)</span>: 邻域半径</li><li><span class="math inline">\(\epsilon\)</span>-邻域:邻域内点的集合</li></ul><p><span class="math display">\[N_{\varepsilon}(p):=\{\text{q in datasetD} \mid \operatorname{dist}(p,q)&lt;=\varepsilon\}\]</span></p><p>【注】<em>距离度量<spanclass="math inline">\(dist(p,q)\)</span>是聚类算法中一个值得探究的问题。此处的距离度量可以为欧氏距离、曼哈顿距离等多种距离度量方式，并且数据点的维度可为任意维度</em></p><ul><li>MinPts: 核心点邻域内数据点的最小数量</li></ul><p><img src="https://images.bumpchicken.cn/img/20220508215638.png" width="50%" height="80%"></p><p>如上图，当MinPts = 4, p的密度相较于q大，p称为高密度点</p><h3 id="核心点边界点和离群点定义">核心点、边界点和离群点定义</h3><p><img src="https://images.bumpchicken.cn/img/20220508220041.png" width="60%" height="60%"></p><ul><li>核心点(Core): 高密度点，其 <spanclass="math inline">\(\epsilon\)</span>-邻域数据点数量 &gt;= MinPts</li><li>边界点(Border): 低密度点，但在某个核心点的邻域内</li><li>离群点(Outlier): 既不是核心点也不是边界点</li></ul><h3 id="密度可达定义">密度可达定义</h3><ul><li>直接密度可达： 如果p是一个核心点，切q在p的<spanclass="math inline">\(\epsilon\)</span>-邻域内，那么称q直接密度可达p</li></ul><p>【注】<em>不能说p直接密度可达q，直接密度可达不具有对称性(symmetric)</em></p><p><img src="https://images.bumpchicken.cn/img/20220508221408.png" width="40%" height="40%"></p><ul><li>密度可达:如果存在一串这样的数据点: <spanclass="math inline">\(p_{1},p_{2},...,p_{n}\)</span>，其中<spanclass="math inline">\(p_{1}=q,p_{n}=p\)</span>,且<spanclass="math inline">\(p_{i+1}\)</span>直接密度可达<spanclass="math inline">\(p_{i}\)</span>，那么称p密度可达q</li></ul><p>【注】<em>不能说q密度可达p，密度可达同样不具有对称性</em></p><p><img src="https://images.bumpchicken.cn/img/20220508222514.png" width="50%" height="50%"></p><h3 id="密度连通">密度连通</h3><p>如果p和q都密度可达点o，那么称p和q密度连通，如下所示</p><p><img src="https://images.bumpchicken.cn/img/20220508224900.png" width="50%" height="50%"></p><p>【注】<em>密度连通具有对称性，可以说q和p密度连通</em></p><h2 id="聚类准则">聚类准则</h2><p>给定一个数据集D，参数<spanclass="math inline">\(\epsilon\)</span>和MinPts，那么聚类产生的子集C必须满足两个准则：</p><ol type="1"><li>Maximality(极大性)：对于任意的p、q，如果<spanclass="math inline">\(p\in C\)</span>，且q密度可达p，那么同样<spanclass="math inline">\(q\in C\)</span></li><li>Connectivity(连通性)：对于任意的p、q，p和q是密度相连的</li></ol><h2 id="聚类流程">聚类流程</h2><p>DBSCAN聚类过程如下图所示</p><p><img src="https://images.bumpchicken.cn/img/20220508225615.png" width="80%" height="80%"></p><h2 id="参数选择">参数选择</h2><h3 id="邻域大小epsilon">邻域大小<spanclass="math inline">\(\epsilon\)</span></h3><p>DBSCAN采用全局<spanclass="math inline">\(\epsilon\)</span>和MinPts值，因此每个节点的邻域大小是一致的。当数据密度和聚簇间距离分布不均匀时，若选取较小的<spanclass="math inline">\(\epsilon\)</span>，则较稀疏的聚簇中的数据点密度会小于MintPts，而被认为是边界点而不被用于所在类的进一步扩展。可能导致较稀疏的聚簇被划分为多个性质相似的小聚簇。相反,若选取较大的<spanclass="math inline">\(\epsilon\)</span>，则离得较近而密度较大的那些聚簇可能被合并为同一个聚簇，他们之间的差异将被忽略。因此这种情况下，选取合适的邻域大小是较为困难的，当维度较高时，<spanclass="math inline">\(\epsilon\)</span>的选取更加困难</p><h3 id="minpts">MinPts</h3><p>参数MinPts的选取有一个指导性原则，即 <spanclass="math inline">\(MinPts &gt;= dim+1\)</span>，这里<spanclass="math inline">\(dim\)</span>表示聚类空间的维度大小</p><h2 id="优缺点">优缺点</h2><h3 id="优点">优点</h3><ol type="1"><li>可以对任意形状的稠密数据集进行聚类（K-Means一般只适用于凸数据集）</li><li>可以在聚类时发现异常点，对数据集的异常点不敏感</li></ol><h3 id="缺点">缺点</h3><ol type="1"><li>如果样本集的密度不均匀，聚类间距相距很大时，聚类效果较差</li><li>对于参数 <span class="math inline">\(\epsilon\)</span>和MinPts敏感，不同参数组合对聚类效果影响较大</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;https://images.bumpchicken.cn/img/20220508173927.png&quot; width=&quot;60%&quot; height=&quot;20%&quot;&gt;&lt;/p&gt;
&lt;p&gt;DBSCAN(Density-Based Spatial Clustering of Application with
Noise)是一种基于密度的空间聚类算法。该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据中发现任意形状的簇，它将簇定义为密度相连的点的最大集合。算法无需事先指定聚类中心数目，可以对大规模无规则形状的数据进行有效聚类。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://www.bumpchicken.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="聚类" scheme="http://www.bumpchicken.cn/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
</feed>
